## Initialization

import copy
import time
import os

import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.init as init
import torch.optim as optim

from torch.utils.data import DataLoader, TensorDataset


use_gpu = torch.cuda.is_available()
device = torch.device("cuda:0" if use_gpu else "cpu")

# Setting the seed to a fixed value can be helpful in reproducing results
seed = 42
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)

print("PyTorch version: ", torch.__version__)
print("GPU available: {}".format(use_gpu))


## Generate the dataset

def generate_data(n_samples, seq_len, input_dim=1, xmin=-100, xmax=100):
    """Generate tensors X and Y within the [xmin, xmax] interval.
    Args : 
      n_samples: int, number of sequences to generate
      seq_len: int, length of each sequence
      input_dim: int, dimension of the input data
      xmin: minimum possible value in the sequence
      xmax: maximum possible value in the sequence
      
    Returns: n_samples sequence of numbers X and associated targets Y in this
             format torch.Tensor where X.shape = (n_samples, seq_len, 1)
             and Y.shape = (n_samples, 1).
    """
    X = torch.randint(xmin, xmax+1, (n_samples, seq_len, input_dim))
    Y = X.sum(dim=1)
    
    return X, Y

## Test the generate_data function

n_samples = 1000
seq_len = 4
input_dim = 1
X, Y = generate_data(n_samples, seq_len, input_dim, -100, 100)
print("Tensor dimensions X = {}".format(X.shape))
print("where n_samples = {}, seq_len = {}, input_dim = {}".format(*X.shape))
print("data example: {}".format(X[0,:,0]))

## Standardize the data

def standardize(X):
    """The function standardizes the X tensor. 
    Args:
      X: torch.Tensor.
    Returns:
      Xs: torch.Tensor standardize.
      Ys: torch.Tensor, the (new) sum of Xs.
      mean: float, the mean of X.
      stdev: float, the stdev of X.
    """
    
    X=X.float()
    mean = torch.mean(X)
    std = torch.std(X)
    Xs = (X-mean) / std
    Ys = Xs.sum(dim=1)
    
    return Xs, Ys, mean, std

## Test the standardize function

X, Y = generate_data(n_samples, seq_len, input_dim, -100, 100)
example_before = X[0,:,0]
Xs, Ys, mean, std = standardize(X)
print("mean = {:.4f}, std = {:.4f}".format(mean, std))
print('example before standardization: {}'.format(X[0,:,0]),
      '\nexample after standardization: {}'.format(Xs[0,:,0])
)


## Implement RNN

class RNNLinear(nn.Module):

    def __init__(self, input_dim, output_dim, hidden_size, n_layers):
        super(RNNLinear, self).__init__()
        # To complete.    

        self.rnn = nn.RNN(input_dim,
                          hidden_size,
                          n_layers) # where in the world does the documentation
                                    # tell you that these are the required inputs?
        self.linear = nn.Linear(hidden_size, output_dim)


    def forward(self, x):
        # The RNN's input must be of size (seq_len, batch_size, input_dim)
        # To complete.        
        
        # My input shape is (n_samples aka 'batch size', seq_len, input_dim)
        # Want input in this shape: seq_len, n_samples, input_dim - so swap 0 and 1

        # Permute can rearrange dimensions E.g., If I have the dimensions
        # x =(A, B, C) and I want to swap A and B, I refer to them by their index. 
        # So do this x.permute(1, 0, 2)
        
        # The RNN's input must be of size (seq_len, batch_size, input_dim)
        
        #x = x.transpose(0, 1) 
        input = x.permute(1,0,2)
      
        output,_ = self.rnn(input)
        pred = self.linear(output[-1]) #NOTE: use [-1] to get only the LAST output from the model
        
        return pred
    
## Test RNN Model

n_samples = 50
seq_len = 4
input_dim = 1
output_dim = 1
n_layers = 2
hidden_size = 20

# Data generation
X, Y = generate_data(n_samples, seq_len, input_dim, -100, 100)
Xs, Ys, mean, std = standardize(X)

print(Xs.size())
print(Xs.permute(1,0,2).size())

# Declaration of the RNN model
model_rnn = RNNLinear(input_dim, output_dim, hidden_size, n_layers)

# Transfer the model to the proper device
model_rnn = model_rnn.to(device)

# save its initial weights
init_rnn_weights = copy.deepcopy(model_rnn.state_dict())

# Transfer the data to the proper device
Xs = Xs.to(device)

# Use the RNN to predict the output of each input sequence prior to training
# Ensure that the inputs and output are correct
y_pred = model_rnn(Xs)
print("Size of input data: {}".format(Xs.shape)) # (n_samples, seq_len, input_dim)
print("Size of predictions: {}".format(y_pred.shape)) # (n_samples, input_dim)


## Implement LSTM Model

